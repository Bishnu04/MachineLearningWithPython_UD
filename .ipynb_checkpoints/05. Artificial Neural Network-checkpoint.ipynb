{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agenda\n",
    "- Deep Learning\n",
    "- Artificial Neural Network(ANN)\n",
    "- How Neural Network Works\n",
    "- Mathematics Behind NN\n",
    "- Activation Function\n",
    "- Bias Node\n",
    "- Forward Propagation\n",
    "- Back Propagation\n",
    "- Learning Rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning\n",
    "- Deep learning (also known as deep structured learning) is part of a broader family of machine learning methods based on artificial neural networks with representation learning. \n",
    "- Learning can be supervised, semi-supervised or unsupervised\n",
    "- The “deep” in deep learning refers to the depth of the network.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/1/18/AI-ML-DL.png\" width=\"400\" />\n",
    "\n",
    "#### Why Deep Learning?\n",
    "\n",
    "<img src=\"Image/perf.png\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network\n",
    "- Dendrites are the structures on the neuron that receive electrical messages, to process these signals, and to transfer the information to the soma of the neuron\n",
    "- Axons: primary transmission lines of the nervous system\n",
    "\n",
    "\n",
    "<img src=\"Image/neuron.jpg\" width=\"400\" />\n",
    "<br>\n",
    "<br>  \n",
    "<br>  \n",
    "<br>\n",
    "<br>\n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How Neural Network Works?\n",
    "<img src=\"Image/neuron-3.png\" width=\"300\" />\n",
    "<br>\n",
    "<br>  \n",
    "<br>  \n",
    "<br>\n",
    "<br>\n",
    "<img src=\"Image/Basic_Neural.png\" width=\"500\" />\n",
    "<br>\n",
    "<br>  \n",
    "<br>  \n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network with Hidden Layer\n",
    "\n",
    "- Between Input and Output layer\n",
    "- Allow for the function of a neural network to be broken down into specific transformations of the data\n",
    "- Each hidden layer function is having specific task to produce a defined output\n",
    "\n",
    "<img src=\"Image/house_neural.png\" width=\"500\" />\n",
    "<br>\n",
    "<br>  \n",
    "<br>  \n",
    "<br>\n",
    "<br>\n",
    "<img src=\"Image/house_hidden.png\" width=\"500\" />\n",
    "<br>\n",
    "<br>  \n",
    "<br>  \n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Function\n",
    "\n",
    "- These type of functions are attached to each neuron in the network, and determines whether it should be activated or not, based on whether each neuron’s input is relevant for the model’s prediction.\n",
    "- It helps to standardize the output of each neuron.\n",
    "- E.g: Threshold, Sigmoid, Relu(Rectifier), Softmax\n",
    "\n",
    "<img src=\"Image/activation.png\" width=\"500\" />\n",
    "\n",
    "#### Whats the diff between Step function, Linear function and Sigmoid function?  \n",
    "\n",
    "\n",
    "Linear Function:\n",
    "- Using Linear function only will make the output layer to be a linear function as well so we can't map a non-linear dataset\n",
    "\n",
    "Step Function: \n",
    "- we define threshold values and have discrete output values\n",
    "- if(z > threshold) — “activate” the node (value 1)\n",
    "- if(z < threshold) — don’t “activate” the node (value 0)\n",
    "- So, we have value either 0 or 1\n",
    "- issue here is that it is possible multiple output classes/nodes to be activated (to have the value 1). So we are not able to properly classify/decide.\n",
    "\n",
    "Sigmoid Function:  \n",
    "\n",
    "$ \\theta(x) = \\frac {1} {1 + e^{-x}} $\n",
    "\n",
    "- It is a non-linear function\n",
    "- Value range is (0,1)\n",
    "- classify values either 1 or 0\n",
    "\n",
    "<img src=\"Image/sigmoid1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "#### Threshold Function\n",
    "\n",
    "$ \\theta(x): $   \n",
    "=0 if x < 0  \n",
    "=1 if x > 0 \n",
    "\n",
    "<img src=\"Image/threshold1.png\" width=\"300\" />\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rectifier Function\n",
    "\n",
    "$ \\theta(x) = max(x,0) $\n",
    "\n",
    "<img src=\"Image/rectifier1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias\n",
    "- Its a constant which helps the model in a way that it can fit best for the given data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do Neural network Learn?\n",
    "\n",
    "- Cost reduces with adjustment in weight(w)\n",
    "<img src=\"Image/neural_learn.png\">\n",
    "\n",
    "## Back Propagation\n",
    "\n",
    "- Error propagates from right to left and update the weights according to how much they are responsible for the error.\n",
    "- Determining how changing the weights impact the overall cost in the neural network.\n",
    "\n",
    "## Learning Rate\n",
    "\n",
    "The learning rate decides by how much we update the weights\n",
    "\n",
    "## Perceptron\n",
    "A collection of neurons, along with a set of input nodes connected to the inputs via weighted edges, is a perceptron, the simplest neural network.\n",
    "\n",
    "<img src=\"Image/neuron-3.png\" width=\"300\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Examples:\n",
    "\n",
    "$ x_1,x_2 \\epsilon (0,1)$  \n",
    "y = x1 AND x2\n",
    "<img src=\"Image/ex-nn.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AND Gate\n",
    "$h_\\theta(x) = g(-50+30x_1+30x_2)$  \n",
    "\n",
    "<img src=\"Image/AND1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR Gate\n",
    "$h_\\theta(x) = g(-20+30x_1+30x_2)$  \n",
    "\n",
    "<img src=\"Image/OR.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-50, 30, 30]\n"
     ]
    }
   ],
   "source": [
    "import numpy, random, os\n",
    "lr = 1 #learning rate\n",
    "bias = 1 #value of bias\n",
    "weights = [-50, 30, 30]\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 85, 30]\n",
      "0\n",
      "1\n",
      "0 or 1 is :  1\n"
     ]
    }
   ],
   "source": [
    "#Training the model\n",
    "def perceptron(x_1, x_2, output) :\n",
    "    outputP = bias*weights[0]+x_2*weights[1]+x_2*weights[2]\n",
    "    if outputP > 4.6 : #activation function (here Heaviside)\n",
    "        outputP = 1\n",
    "    else :\n",
    "        outputP = 0\n",
    "    #print(output,outputP)    \n",
    "    error = (output-outputP)**2\n",
    "    #print(error)\n",
    "    weights[0] += error * bias * lr\n",
    "    weights[1] += error * x_1 * lr\n",
    "    weights[2] += error * x_2 * lr\n",
    "\n",
    "    #print (weights)\n",
    "\n",
    "#Making the prediction\n",
    "def predict(x_1, x_2):\n",
    "    outputP = bias*weights[0] + x*weights[1] + y*weights[2] \n",
    "    if outputP > 4.6: #activation function\n",
    "        outputP = 1\n",
    "    else :\n",
    "        \n",
    "        outputP = 0\n",
    "    return outputP\n",
    "    \n",
    "for i in range(10) :\n",
    "    #print(\"Running loop i=%s\"%i)\n",
    "    perceptron(1,1,1) #True or true\n",
    "    perceptron(1,0,1) #True or false\n",
    "    perceptron(0,1,1) #False or true\n",
    "    perceptron(0,0,0) #False or false\n",
    "print(weights)     \n",
    "x = int(input())\n",
    "y = int(input())\n",
    "output_predict = predict(x, y )\n",
    "print(x, \"or\", y, \"is : \", output_predict)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Two Types:\n",
    "1. Batch Gradient Descent\n",
    "2. Stochastic Gradient Descent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
